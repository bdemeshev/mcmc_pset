\Opensolutionfile{solution_file}[solutions/sols_000]
% в квадратных скобках фактическое имя файла

\chapter{Неразобранные :)}



\begin{problem}
Шахматный конь начинает в клетке A1. Каждый свой ход он выбирает равновероятно из возможных. Какова вероятность того, что через много-много ходов он окажется в клетке H8? Сколько в среднем длится путь от клетки A1 до клетки A1?
\begin{sol}
\end{sol}
\end{problem}

\begin{problem}
Случайные величины $X_i$ независимы и одинаково распределены с табличкой

\begin{tabular}{c|ccc}
$X$ & 1 & 2 & 6 \\ 
\hline 
$\P()$ & $\beta$ & $2\beta$ & $1-3\beta$ \\ 
\end{tabular} 

Известно, что $X_1=1$, $X_2=2$, $X_3=2$, $X_4=4$. 
\begin{enumerate}
\item Найдите оценку $\hat{\beta}$ методом моментов
\item Найдите оценку $\hat{\beta}$ методом максимального правдоподобия
\item Предположим, что $\beta$ равномерно на отрезке $[0;1/3]$. Найдите апостериорную условную функцию плотности $\beta$ с учётом полученных наблюдений. С какой функцией она совпадает?
\item Предположим, что $\beta$ имеет функцию плотности $f(t)=18t$ на отрезке $[0;1/3]$. Найдите апостериорную функцию плотности $\beta$. 
\end{enumerate}
\begin{sol}
\end{sol}
\end{problem}


\begin{problem}
Используя алгоритм Метрополиса-Хастингса сгенерите выборку для биномиального распределения $Bin(n,p)$ из равновероятного на множестве $\{0,1,2,\ldots,n\}$
\begin{sol}
\end{sol}
\end{problem}

\begin{problem}
Используя алгоритм Метрополиса-Хастингса сгенерите выборку для биномиального распределения $Bin(n,p)$ из симметричного случайного блуждания на $\ZZ$
\begin{sol}
\end{sol}
\end{problem}

\begin{problem}
Используя алгоритм Метрополиса-Хастингса сгенерите выборку для геометрического распределения $Geom(p)$ из симметричного случайного блуждания на $\ZZ$
\begin{sol}
\end{sol}
\end{problem}

\begin{problem}
Используя алгоритм Метрополиса-Хастингса сгенерите выборку для пуассоновского распределения $Pois(\lambda)$ из симметричного случайного блуждания на $\ZZ$
\begin{sol}
\end{sol}
\end{problem}

\begin{problem}
Используя алгоритм Метрополиса-Хастингса сгенерите выборку для функции плотности $\pi(x)\sim \exp(-x^2)(3+x^2+\cos x)$ из нормального $N(0,1)$. Из нормального $N(0,\sigma^2)$
\begin{sol}
\end{sol}
\end{problem}

\begin{problem}
Используя алгоритм Метрополиса-Хастингса сгенерите выборку для функции плотности $\pi(x)\sim \exp(-x^2)(3+x^2+\cos x)$ из случайного блуждания $X_{t+1}=X_t+\varepsilon_t$, где $\varepsilon_t\sim N(0,1)$. Вариант с $N(0,\sigma^2)$
\begin{sol}
\end{sol}
\end{problem}

\begin{problem}
Используя алгоритм Метрополиса-Хастингса сгенерите выборку для стандартного нормального распределения $N(0,1)$ из случайного блуждания $X_{t+1}=X_t+\varepsilon_t$, где $\varepsilon_t\sim U[-1,1]$
\begin{sol}
\end{sol}
\end{problem}

\begin{problem}
Используя алгоритм Метрополиса-Хастингса сгенерите выборку для двумерного нормального распределения $N(0,A)$, $A=\left(\begin{array}{cc}
4 & -1 \\ 
-1 & 2
\end{array}\right)$  
из случайного блуждания 
$X_{t+1,i}=X_{t,i}+\varepsilon_{t,i}$, 
где $\varepsilon_{t,i}\sim U[-1,1]$.
\begin{sol}
\end{sol}
\end{problem}

\begin{problem}
Используя алгоритм Метрополиса-Хастингса сгенерите выборку для двумерного распределения с функцией плотности 
$p(x,y)=\exp(-4x^2-6y^2+2x-y+xy)$, $x>0$, $y>0$ из случайного блуждания 
$X_{t+1,i}=X_{t,i}+\varepsilon_{t,i}$, 
где $\varepsilon_{t,i}\sim U[-1,1]$.
\begin{sol}
\end{sol}
\end{problem}

\begin{problem}
Рассмотрим модель
\[
y = X\beta + u, 
\]
где $u_i$ независимы и $\cN(0; \sigma^2)$.

Метод гребневой регрессии предполагает минимизацию функции
\[
Q(\beta) = \sum_{i=1}^n (y_i - \hat y_i)^2 + \lambda \sum_{j=1}^k \beta_j^2.
\]

Рассмотрим байесовский подход к регрессии. Предположим, что априорное распределение имеет вид $\sigma^2 \sim InvGamma(a, b)$, $\beta_j|\sigma^2 \sim \cN(0; c)$.

При каких $a$, $b$ и $c$ апостериорная мода $\hat\beta_{MAP}$ совпадёт с $\hat\beta_{Ridge}$?
\begin{sol}
\end{sol}
\end{problem}

\begin{problem}
Рассмотрим модель
\[
y = X\beta + u, 
\]
где $u_i$ независимы и $\cN(0; \sigma^2)$.

Метод LASSO предполагает минимизацию функции
\[
Q(\beta) = \sum_{i=1}^n (y_i - \hat y_i)^2 + \lambda \sum_{j=1}^k |\beta_j|.
\]

Рассмотрим байесовский подход к регрессии. Предположим, что априорное распределение имеет вид $\sigma^2 \sim InvGamma(a, b)$, $\beta_j|\sigma^2 \sim DoubleExp(c)$.

При каких $a$, $b$ и $c$ апостериорная мода $\hat\beta_{MAP}$ совпадёт с $\hat\beta_{LASSO}$?
\begin{sol}
\end{sol}
\end{problem}



\Closesolutionfile{solution_file}
